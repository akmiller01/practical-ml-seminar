{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages (optional if already used pip and requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets\n",
    "# ! pip install accelerate\n",
    "# ! pip install evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/git/practical-ml-seminar/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased', model_max_length=512)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)\n",
    "\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load dataset\n",
    "- Calculate id2label and label2id dictionaries\n",
    "- Label, shuffle, stratify, and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting to class labels: 100%|██████████| 3878/3878 [00:00<00:00, 253831.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/GB-GOV-1.csv')\n",
    "unique_labels = df.label.unique()\n",
    "id2label = {i: label for i, label in enumerate(unique_labels)}\n",
    "label2id = {id2label[i]: i for i in id2label.keys()}\n",
    "dataset = Dataset.from_pandas(df).class_encode_column(\"label\").train_test_split(\n",
    "    test_size=0.3,\n",
    "    stratify_by_column=\"label\",\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2714/2714 [00:00<00:00, 17828.03 examples/s]\n",
      "Map: 100%|██████████| 1164/1164 [00:00<00:00, 22385.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_data = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert/distilbert-base-uncased', num_labels=len(id2label.keys()), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up training arguments and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='models/climate-classifier',\n",
    "    learning_rate=1e-5, # This can be tweaked depending on how loss progresses\n",
    "    per_device_train_batch_size=36, # These should be tweaked to match GPU VRAM\n",
    "    per_device_eval_batch_size=36,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data['train'],\n",
    "    eval_dataset=tokenized_data['test'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 10%|█         | 76/760 [02:43<21:11,  1.86s/it]Checkpoint destination directory models/climate-classifier/checkpoint-76 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43150314688682556, 'eval_accuracy': 0.8213058419243986, 'eval_runtime': 21.0315, 'eval_samples_per_second': 55.345, 'eval_steps_per_second': 1.569, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 152/760 [05:40<15:15,  1.51s/it]Checkpoint destination directory models/climate-classifier/checkpoint-152 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38561081886291504, 'eval_accuracy': 0.834192439862543, 'eval_runtime': 16.5845, 'eval_samples_per_second': 70.186, 'eval_steps_per_second': 1.99, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 30%|███       | 228/760 [08:31<14:30,  1.64s/it]Checkpoint destination directory models/climate-classifier/checkpoint-228 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3669620752334595, 'eval_accuracy': 0.8436426116838488, 'eval_runtime': 22.3838, 'eval_samples_per_second': 52.002, 'eval_steps_per_second': 1.474, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 40%|████      | 304/760 [11:44<12:53,  1.70s/it]Checkpoint destination directory models/climate-classifier/checkpoint-304 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3765120506286621, 'eval_accuracy': 0.8496563573883161, 'eval_runtime': 20.38, 'eval_samples_per_second': 57.115, 'eval_steps_per_second': 1.619, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 50%|█████     | 380/760 [14:46<11:05,  1.75s/it]Checkpoint destination directory models/climate-classifier/checkpoint-380 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38608911633491516, 'eval_accuracy': 0.8479381443298969, 'eval_runtime': 21.7681, 'eval_samples_per_second': 53.473, 'eval_steps_per_second': 1.516, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 60%|██████    | 456/760 [17:53<10:22,  2.05s/it]Checkpoint destination directory models/climate-classifier/checkpoint-456 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41391292214393616, 'eval_accuracy': 0.8487972508591065, 'eval_runtime': 24.7514, 'eval_samples_per_second': 47.028, 'eval_steps_per_second': 1.333, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 500/760 [19:42<11:19,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.323, 'learning_rate': 3.421052631578948e-06, 'epoch': 6.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 70%|███████   | 532/760 [21:19<06:53,  1.82s/it]Checkpoint destination directory models/climate-classifier/checkpoint-532 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42547136545181274, 'eval_accuracy': 0.8530927835051546, 'eval_runtime': 21.8064, 'eval_samples_per_second': 53.379, 'eval_steps_per_second': 1.513, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 80%|████████  | 608/760 [24:20<04:44,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43231654167175293, 'eval_accuracy': 0.8419243986254296, 'eval_runtime': 17.6946, 'eval_samples_per_second': 65.783, 'eval_steps_per_second': 1.865, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 90%|█████████ | 684/760 [27:16<02:10,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4386640787124634, 'eval_accuracy': 0.8445017182130584, 'eval_runtime': 22.6799, 'eval_samples_per_second': 51.323, 'eval_steps_per_second': 1.455, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 760/760 [30:05<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4387195110321045, 'eval_accuracy': 0.8470790378006873, 'eval_runtime': 18.77, 'eval_samples_per_second': 62.014, 'eval_steps_per_second': 1.758, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [30:06<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1806.9874, 'train_samples_per_second': 15.019, 'train_steps_per_second': 0.421, 'train_loss': 0.26499609696237664, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=760, training_loss=0.26499609696237664, metrics={'train_runtime': 1806.9874, 'train_samples_per_second': 15.019, 'train_steps_per_second': 0.421, 'train_loss': 0.26499609696237664, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
